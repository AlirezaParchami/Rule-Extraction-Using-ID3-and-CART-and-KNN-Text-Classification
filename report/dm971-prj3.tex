% !TeX program = xelatex
\documentclass[a4paper,12pt]{article}

\usepackage{tabularx}
\usepackage[font=small,labelfont=bf]{caption}
\usepackage{graphicx}
\usepackage[localise=on]{xepersian}

\settextfont{XB Yas}
\linespread{1.25}

\title{گزارش پروژه سوم درس داده‌کاوی}

\author{
پرهام کاظمی \\ ۹۴۳۶۱۱۰۴۳۰۱۸
\and
علیرضا پرچمی \\ ۹۴۳۶؟؟
}

\begin{document}
	\maketitle
	
\قسمت*{مقدمه}

\پاراگراف{} 
هدف از این پروژه، استفاده از الگوریتم‌های دسته‌بندی \پانویس{classification} برای داده‌کاوی و کشف حقایق در مجموعه‌داده‌ی \متن‌لاتین{Mushroom} می‌باشد.

\پاراگراف{}
در ابتدا، با استفاده از الگوریتم \متن‌لاتین{K-Folds Cross-Validation}، مجموعه‌داده، ۱۰ بار به مجموعه‌داده‌های آموزش و آزمایش قطعه‌بندی شده است. سپس، با تشکیل درخت‌های \متن‌لاتین{ID3} و \متن‌لاتین{CART}، قوانین مورد استفاده برای دسته‌بندی استخراج و دقت و صحت درخت‌ها به کمک معیارهای \متن‌لاتین{F-Measure} و \متن‌لاتین{Presicion} و \متن‌لاتین{Recall} محاسبه شده‌اند. 

\پاراگراف{}
در نهایت، الگوریتم دسته‌بندی K نزدیک‌ترین همسایه \پانویس{K-Nearest Neigbours} بر روی مجموعه‌داده‌های آموزش و آزمایش - که با روش \متن‌لاتین{hold out} تقسیم‌بندی شده‌اند - اجرا شده و دقت دسته‌بند با توجه به معیارهای  \متن‌لاتین{F-Measure} و \متن‌لاتین{Presicion} و \متن‌لاتین{Recall} محاسبه شده‌ است.
	
	\قسمت{ابزارهای استفاده شده}
	
	\پاراگراف{}
	در پیاده‌سازی این پروژه، از کتاب‌خانه‌های زیر در زبان پایتون استفاده شده است:
	
	\شروع{توضیح}
		 \فقره[\متن‌لاتین{jupyter}] برای پیاده‌سازی و استفاده از الگوریتم‌های موجود در کتاب‌خانه‌ها در محیطی مناسب.
		\فقره[\متن‌لاتین{scikit-learn}] شامل پیاده‌سازی الگوریتم‌های تولید درخت‌های تصمیم‌گیری و \متن‌لاتین{KNN} و همین‌طور محاسبه‌ی معیارهای اندازه‌گیری دقت دسته‌بندهای به‌دست‌آمده.
		\فقره[\متن‌لاتین{pandas}] جهت خواندن داده‌ها از فایل و آماده‌سازی و پیش‌پردازش آن‌ها.
		\فقره[\متن‌لاتین{graphviz}] برای نمایش گراف‌ها و درخت‌های تولید شده و ذخیره‌ی خروجی در فایل \متن‌لاتین{pdf}.
	\پایان{توضیح}
	
	\قسمت{مجموعه‌داده}
	
	\پاراگراف{}
	توضیحات دیتاست
	
	\قسمت{درخت تصمیم}
	
	\پاراگراف{} 
	درخت‌های تصمیم، نوعی از دسته‌بندها می‌باشند که با تقسیم‌بندی‌های متوالی مجموعه‌داده در هر گره و تصمیم در یال‌های درخت، کلاس هر نمونه‌ی ورودی را تعیین می‌کنند. در این پروژه، از دو روش استفاده از آنتروپی (درخت‌های \متن‌لاتین{ID3}) و معیار \متن‌لاتین{GINI} (در درخت \متن‌لاتین{CART})، دو دسته‌بند به دست آمده و از نظر دقت با هم مقایسه شده‌اند.
	
		\زیرقسمت{پیش‌پردازش داده‌ها}
		در این مجموعه‌داده، ستون ۱۱اُم که بیانگر ویژگی \متن‌لاتین{stalk-root} است، دارای مقادیر گم‌شده می‌باشد. برای رفع این مشکل، در نمونه‌هایی که دارای مقدار ناقص برای این ویژگی می‌باشند، مقدار «؟» با مُد داده‌های موجود در این ستون جایگزین شده‌اند. دلیل این کار، اسمی بودن ویژگی‌های موجود می‌باشد. بدین منظور، قطعه‌کد زیر با استفاده از کتاب‌خانه \متن‌لاتین{pandas} اجرا شده است:
		\begin{flushleft}
		\lr{\texttt{
			import pandas as pd \\
			m11 = data.mode()['stalk-root'][0] \\
			data.loc[data['stalk-root'] == '?', 'stalk-root'] = m11
		}}
	\end{flushleft}
\پاراگراف{} در این قطعه‌کد، ابتدا فراوان‌ترین مقدار ویژگی مورد نظر در متغیر \متن‌لاتین{\متن‌تایپ{m11}} ذخیره شده و سپس مقادیر مشخص شده با «؟»، توسط مُد به‌دست‌آمده جایگزین شده‌اند.
	
	\زیرقسمت{تقسیم‌بندی مجموعه‌داده}
	
	\پاراگراف{}
	برای تقسیم‌بندی مجموعه‌داده به دو دسته‌ی آموزش و آزمایش، از روش \متن‌لاتین{K-Folds Cross-Validation} استفاده شده است. در این روش، مجموعه‌داده در ابتدا به K مجموعه‌ی کوچک‌تر تقسیم شده و برای ایجاد هر مدل، یکی از زیرمجموعه‌ها به عنوان داده‌ی آزمایش و سایر داده‌های موجود، برای آموزش مدل مورد استفاده قرار می‌گیرند. برای تولید درخت‌های تصمیم‌گیری، پارامتر K برابر ۱۰ فرض شده است. الگوریتم \متن‌لاتین{K-Folds} در کتاب‌خانه‌ی \متن‌لاتین{scikit-learn} به صورت زیر استفاده می‌شود:
	\begin{flushleft}
		\lr{\texttt{
				from sklearn.model\_selection import KFold \\
				sets = KFold(n\_splits=10)
		}}
	\end{flushleft}
	
	\زیرقسمت{ایجاد درخت \متن‌لاتین{ID3}}
	
\پاراگراف{}
در کتاب‌خانه‌ی \متن‌لاتین{scikit-learn}، درخت‌های تصمیم‌گیری با استفاده از کلاس \متن‌تایپ{DecisionTreeClassifier} تولید می‌شوند. در ورودی تابع سازنده این کلاس، پارامتر \متن‌تایپ{criterion} نوع درخت مورد نظر را تعیین می‌کند. برای ایجاد درخت \متن‌لاتین{ID3}، مقدار \متن‌تایپ{'entropy'} به این پارامتر تخصیص داده می‌شود. سپس با فراخوانی متد‌های \متن‌تایپ{fit} و \متن‌تایپ{predict}، به ترتیب داده‌های آموزش و آزمایش را در اختیار الگوریتم قرار می‌دهیم:
\begin{flushleft}
	\lr{\texttt{
			dt = DecisionTreeClassifier(criterion='entropy') \\
			dt.fit(X\_train, y\_train) \\
			y\_pred = dt.predict(X\_test)
	}}
\end{flushleft}

\پاراگراف{}
سپس با استفاده از کتاب‌خانه‌ی \متن‌لاتین{scikit-learn}، دقت کلاس‌های به‌دست‌آمده برای مجموعه‌داده‌ی آزمایش (\متن‌لاتین{y\_pred}) محاسبه می‌شود:
\begin{flushleft}
	\lr{\texttt{
			from sklearn.metrics import precision\_recall\_fscore\_support \\
			presicion, recall, f\_measure, \_ = precision\_recall\_fscore\_support(y\_test, y\_pred, average='micro')
	}}
\end{flushleft}

\پاراگراف{}
درخت حاصل و همین‌طور دقت‌های به‌دست‌آمده در فایل خروجی (\متن‌لاتین{decision\_trees.html}) قابل مشاهده می‌باشند.
	
	\زیرقسمت{ایجاد درخت \متن‌لاتین{CART}}
	
	\زیرقسمت{مقایسه‌ی درخت‌ها}
	
	\زیرقسمت{استخراج قوانین از درخت تصمیم}
	
	\قسمت{الگوریتم KNN}
	
	\پاراگراف{}
	توضیحات الگوریتم
	
	\زیرقسمت{تقسیم‌بندی مجموعه‌داده}
	
	\زیرقسمت{پیاده‌سازی و اجرای الگوریتم}
	
	\زیرقسمت{بررسی دقت و صحت}
	
\end{document}